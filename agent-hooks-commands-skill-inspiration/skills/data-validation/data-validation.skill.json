{
  "name": "data-validation",
  "version": "1.0.0",
  "description": "Data validation orchestrator with domain expertise in data quality, integrity, schema compliance, statistical analysis, and anomaly detection. Validates datasets and provides quality assurance recommendations.",
  "type": "skill",
  "tier": 2,
  "model": "sonnet",
  "capabilities": [
    "data-validation",
    "quality-assurance",
    "schema-checking",
    "anomaly-detection",
    "completeness-check",
    "consistency-check",
    "accuracy-validation",
    "statistical-analysis",
    "data-integrity"
  ],
  "input": {
    "type": "object",
    "description": "Data validation request with scope and focus",
    "properties": {
      "goal": {
        "type": "string",
        "description": "What to validate (e.g., 'Validate customer dataset')"
      },
      "scope": {
        "type": "string",
        "description": "Data file or pattern (e.g., 'data/customers.csv')"
      },
      "focus": {
        "type": "array",
        "items": {
          "type": "string",
          "enum": ["completeness", "consistency", "accuracy", "validity", "uniqueness", "timeliness"]
        },
        "description": "Quality dimensions to check"
      },
      "schema": {
        "type": "object",
        "description": "Expected data schema for validation",
        "optional": true
      },
      "standards": {
        "type": "array",
        "items": {
          "type": "string"
        },
        "description": "Standards to verify against (e.g., ['Business rules', 'Data quality framework'])",
        "optional": true
      }
    }
  },
  "output": {
    "type": "object",
    "description": "Validation report with quality scores and issues",
    "properties": {
      "success": {
        "type": "boolean",
        "description": "Whether validation completed successfully"
      },
      "validation": {
        "type": "object",
        "properties": {
          "summary": {
            "type": "string",
            "description": "High-level summary of validation results"
          },
          "quality_dimensions": {
            "type": "object",
            "description": "Scores for each quality dimension (0-100)"
          },
          "issues": {
            "type": "array",
            "description": "Data quality issues with severity and recommendations"
          },
          "recommendations": {
            "type": "array",
            "description": "Actionable recommendations to improve data quality"
          }
        }
      },
      "metadata": {
        "type": "object",
        "properties": {
          "records_validated": {
            "type": "number"
          },
          "fields_checked": {
            "type": "number"
          },
          "anomalies_detected": {
            "type": "number"
          },
          "duration_ms": {
            "type": "number"
          }
        }
      }
    }
  },
  "invocation_patterns": [
    "Validate customer dataset before import",
    "Check data quality",
    "Verify transaction data integrity",
    "Audit dataset for completeness",
    "Detect anomalies in financial data",
    "Validate schema compliance",
    "Find duplicate records"
  ],
  "delegates_to": [
    "read-file",
    "parse-csv",
    "parse-json",
    "check-schema",
    "validate-types",
    "detect-anomalies",
    "calculate-statistics",
    "detect-duplicates",
    "format-output"
  ],
  "methodology": "tactical-4d",
  "domain_expertise": {
    "areas": [
      "Data Analytics",
      "Data Quality",
      "Statistical Analysis",
      "Data Integrity",
      "Business Intelligence"
    ],
    "quality_dimensions": [
      "Completeness",
      "Consistency",
      "Accuracy",
      "Validity",
      "Uniqueness",
      "Timeliness"
    ],
    "validation_methods": [
      "Schema Validation",
      "Type Checking",
      "Statistical Anomaly Detection (IQR, Z-Score)",
      "Referential Integrity Checking",
      "Business Rule Validation",
      "Duplicate Detection"
    ]
  },
  "analysis_chains": {
    "standard": [
      "read-file",
      "parse-csv/parse-json",
      "check-schema",
      "validate-types",
      "detect-anomalies",
      "calculate-statistics",
      "format-output"
    ],
    "completeness": [
      "read-file",
      "parse-csv/parse-json",
      "check-missing-values",
      "calculate-completeness",
      "detect-patterns",
      "format-output"
    ],
    "consistency": [
      "read-file",
      "parse-csv/parse-json",
      "check-referential-integrity",
      "detect-duplicates",
      "validate-ranges",
      "detect-conflicts",
      "format-output"
    ]
  },
  "keywords": [
    "data",
    "validation",
    "quality",
    "integrity",
    "schema",
    "anomaly",
    "completeness",
    "consistency",
    "accuracy",
    "audit",
    "verify",
    "check"
  ],
  "domain": "data-analytics",
  "error_recovery_levels": 5,
  "batch_processing": true,
  "max_records_per_batch": 100000,
  "author": "Maestro System",
  "license": "MIT"
}
